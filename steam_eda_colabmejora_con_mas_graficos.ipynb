{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM_Yfsh3OURH"
      },
      "source": [
        "# Steam Store Games EDA Notebook - Versi√≥n Ejecutiva\n",
        "\n",
        "Este notebook est√° preparado para Google Colab y contiene un an√°lisis completo y profesional del dataset Steam Store Games, listo para presentar a la direcci√≥n. Cada secci√≥n est√° en celdas separadas con explicaci√≥n, gr√°ficos y conclusiones."
      ],
      "id": "sM_Yfsh3OURH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g03rLm0COURN"
      },
      "source": [
        "## 1. Setup del entorno y librer√≠as\n",
        "- Instala pandas, numpy, matplotlib, seaborn, bokeh y sklearn si no est√°n presentes.\n",
        "- Bokeh se usa para gr√°ficos interactivos y matplotlib/seaborn para visualizaciones cl√°sicas."
      ],
      "id": "g03rLm0COURN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1LGjNQkOURP"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    HAVE_MPL = True\n",
        "except:\n",
        "    HAVE_MPL = False\n",
        "try:\n",
        "    import seaborn as sns\n",
        "    HAVE_SEABORN = True\n",
        "except:\n",
        "    HAVE_SEABORN = False\n",
        "try:\n",
        "    from bokeh.plotting import figure, output_file, save\n",
        "    HAVE_BOKEH = True\n",
        "except:\n",
        "    HAVE_BOKEH = False\n",
        "try:\n",
        "    from sklearn.preprocessing import MultiLabelBinarizer\n",
        "    HAVE_MLB = True\n",
        "except:\n",
        "    HAVE_MLB = False"
      ],
      "id": "a1LGjNQkOURP",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUGOT6-3OURR"
      },
      "source": [
        "## 2. Carga de datos\n",
        "Sube `steam.csv` a la carpeta `data/` y aseg√∫rate de que tenga el formato correcto."
      ],
      "id": "WUGOT6-3OURR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "7wxMRp5QOURT",
        "outputId": "782b23b9-ea39-4f2c-fada-082b0fd5352e"
      },
      "source": [
        "DATA_DIR = Path('data')\n",
        "CSV_PATH = DATA_DIR / 'steam.csv'\n",
        "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
        "print(f'Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas')\n",
        "df.head()"
      ],
      "id": "7wxMRp5QOURT",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/steam.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2230685682.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mCSV_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'steam.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/steam.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCg8wgejOURU"
      },
      "source": [
        "## 3. Limpieza y preprocesado detallado\n",
        "- Tratamiento de duplicados y nulos.\n",
        "- Conversi√≥n de fechas y normalizaci√≥n de precios.\n",
        "- Parseo de owners y campos compuestos (genres, tags, platforms)."
      ],
      "id": "wCg8wgejOURU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvzjLokUOURU"
      },
      "source": [
        "# Limpiar nombres de columna\n",
        "df.columns = [c.strip() if isinstance(c,str) else c for c in df.columns]\n",
        "\n",
        "# Parsear fechas\n",
        "date_col = [c for c in df.columns if 'date' in c.lower()]\n",
        "if date_col:\n",
        "    date_col = date_col[0]\n",
        "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
        "else:\n",
        "    date_col = None\n",
        "\n",
        "# Preprocesar precios\n",
        "price_col = [c for c in df.columns if 'price' in c.lower() or 'cost' in c.lower()]\n",
        "if price_col:\n",
        "    price_col = price_col[0]\n",
        "    df[price_col] = df[price_col].astype(str).str.replace('√Ç','',regex=False)\n",
        "    df[price_col] = df[price_col].str.replace(r'\\$','',regex=True).str.replace(',','')\n",
        "    df[price_col] = pd.to_numeric(df[price_col].replace('nan', np.nan), errors='coerce')\n",
        "else:\n",
        "    price_col = None"
      ],
      "id": "IvzjLokUOURU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 juegos por total de reviews\n",
        "if 'positive_ratings' in df.columns and 'negative_ratings' in df.columns:\n",
        "    df['total_reviews'] = df['positive_ratings'] + df['negative_ratings']\n",
        "\n",
        "    top10_games = df.sort_values('total_reviews', ascending=False).head(10)\n",
        "\n",
        "    # Convertir a miles para eje Y\n",
        "    positive_k = top10_games['positive_ratings']\n",
        "    negative_k = top10_games['negative_ratings']\n",
        "\n",
        "    # Preparar gr√°fico\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.plot(top10_games['name'], positive_k, marker='o', label='Reviews Positivas', color='green')\n",
        "    plt.plot(top10_games['name'], negative_k, marker='o', label='Reviews Negativas', color='red')\n",
        "\n",
        "    plt.ylabel('N√∫mero de Reviews (millones)')\n",
        "    plt.xlabel('Juego')\n",
        "    plt.title('Top 10 Juegos por N√∫mero Total de Reviews')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Las columnas 'positive_ratings' o 'negative_ratings' no existen en el dataset.\")"
      ],
      "metadata": {
        "id": "XohAC6PMbB_Y"
      },
      "id": "XohAC6PMbB_Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seleccionamos solo las columnas num√©ricas relevantes (precio y rese√±as) para evitar errores en los c√°lculos estad√≠sticos y simplificar el an√°lisis.\n",
        "## Esto crea un subconjunto limpio llamado df_num, ideal para c√°lculos y gr√°ficas."
      ],
      "metadata": {
        "id": "jIQZcXPYfIku"
      },
      "id": "jIQZcXPYfIku"
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = ['price', 'positive_ratings', 'negative_ratings', 'total_reviews']\n",
        "\n",
        "df_num = df[numeric_cols].dropna()\n",
        "df_num.head()\n"
      ],
      "metadata": {
        "id": "Zb7muxzqbHgA"
      },
      "id": "Zb7muxzqbHgA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generamos un mapa de calor para visualizar c√≥mo se relacionan num√©ricamente las variables entre s√≠.\n",
        "## Esto permite detectar si una variable explica a otra (por ejemplo, m√°s reviews positivas ‚Üí m√°s reviews negativas)."
      ],
      "metadata": {
        "id": "AejndoYafWmF"
      },
      "id": "AejndoYafWmF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## El heatmap muestra c√≥mo se relacionan las variables:\n",
        "\n",
        "Valores cercanos a 1 ‚Üí correlaci√≥n positiva fuerte\n",
        "\n",
        "Cercanos a -1 ‚Üí correlaci√≥n negativa\n",
        "\n",
        "Cercanos a 0 ‚Üí relaci√≥n d√©bil\n"
      ],
      "metadata": {
        "id": "ThqmO1IddRol"
      },
      "id": "ThqmO1IddRol"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sQe5PQdTPG9B"
      },
      "id": "sQe5PQdTPG9B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.heatmap(df_num.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Mapa de calor de correlaciones entre variables\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5kg0rH0JdBF2"
      },
      "execution_count": null,
      "outputs": [],
      "id": "5kg0rH0JdBF2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hacemos un histograma con KDE para observar la distribuci√≥n de precios, y analizar la mayoria de los prescios que existen si son caros o baratos\n"
      ],
      "metadata": {
        "id": "QVAjgVtbfjT9"
      },
      "id": "QVAjgVtbfjT9"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df['price'].dropna(), bins=50, kde=True)\n",
        "plt.title(\"Distribuci√≥n de Precios de los Juegos\")\n",
        "plt.xlabel(\"Precio (‚Ç¨)\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-sYnN5qKdIK9"
      },
      "id": "-sYnN5qKdIK9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculamos la media y desviaci√≥n est√°ndar del precio para superponer una curva normal te√≥rica.\n",
        "## Esto nos permite ver si la distribuci√≥n real sigue una forma normal o est√° sesgada."
      ],
      "metadata": {
        "id": "9TW7fHQsfyne"
      },
      "id": "9TW7fHQsfyne"
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "x = df['price'].dropna()\n",
        "mu, sigma = x.mean(), x.std()\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "\n",
        "# Histograma en frecuencia real\n",
        "counts, bins, patches = plt.hist(x, bins=50, edgecolor='black')\n",
        "\n",
        "# Rango del eje X\n",
        "plt.xlim(0, 100)\n",
        "\n",
        "# C√°lculo de la curva normal escalada al histograma\n",
        "bin_width = bins[1] - bins[0]           # anchura de cada barra\n",
        "scale_factor = len(x) * bin_width        # para que coincida con las frecuencias\n",
        "\n",
        "xs = np.linspace(0, 100, 300)\n",
        "normal_curve = stats.norm.pdf(xs, mu, sigma) * scale_factor\n",
        "\n",
        "plt.plot(xs, normal_curve, color='red', linewidth=2, label=\"Distribuci√≥n Normal (escalada)\")\n",
        "\n",
        "plt.title(\"Histograma de Precios con Distribuci√≥n Normal Ajustada\")\n",
        "plt.xlabel(\"Precio (‚Ç¨)\")\n",
        "plt.ylabel(\"N√∫mero de juegos\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R3FQrx4vdcNT"
      },
      "id": "R3FQrx4vdcNT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Como podemos ver esos outliers, seg√∫n nuestra investigaci√≥n se debe a ediciones especiales de Steam por eso aparecen como ven en la siguiente gr√°fica."
      ],
      "metadata": {
        "id": "GuT6xU3vhZ92"
      },
      "id": "GuT6xU3vhZ92"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x=df['price'])\n",
        "plt.title(\"Boxplot de Precio ‚Äî Detecci√≥n de Outliers\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rzNNZHx-dlsu"
      },
      "id": "rzNNZHx-dlsu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creo tres distribuciones artificiales para visualizar el concepto de sesgo:\n",
        "## negativo, sim√©trico y positivo.\n",
        "## Esto ayuda a interpretar si el precio o reviews de Steam presentan sesgo real. revisar"
      ],
      "metadata": {
        "id": "7v5d3ROIh-I7"
      },
      "id": "7v5d3ROIh-I7"
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,3, figsize=(15,4))\n",
        "\n",
        "sns.histplot(stats.skewnorm.rvs(-8, size=5000), kde=True, ax=ax[0])\n",
        "ax[0].set_title(\"Sesgo Negativo\")\n",
        "\n",
        "sns.histplot(np.random.normal(0,1,5000), kde=True, ax=ax[1])\n",
        "ax[1].set_title(\"Distribuci√≥n Sim√©trica\")\n",
        "\n",
        "sns.histplot(stats.skewnorm.rvs(8, size=5000), kde=True, ax=ax[2])\n",
        "ax[2].set_title(\"Sesgo Positivo\")\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "5BFEUmHEeBR3"
      },
      "id": "5BFEUmHEeBR3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## La PMF muestra la probabilidad exacta de cada valor discreto.\n",
        "## En este caso, vemos qu√© edades requeridas son m√°s frecuentes en los juegos de Steam.\n",
        "## Sirve para entender c√≥mo se distribuyen categor√≠as discretas."
      ],
      "metadata": {
        "id": "iacubDNIjO1l"
      },
      "id": "iacubDNIjO1l"
    },
    {
      "cell_type": "code",
      "source": [
        "if 'required_age' in df.columns:\n",
        "    pmf = df['required_age'].value_counts(normalize=True).sort_index()\n",
        "\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.bar(pmf.index, pmf.values)\n",
        "    plt.title(\"PMF ‚Äî Probabilidad de Edades Requeridas\")\n",
        "    plt.xlabel(\"Edad\")\n",
        "    plt.ylabel(\"Probabilidad\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "UXAEKKINeOBw"
      },
      "id": "UXAEKKINeOBw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegurar que la columna existe y convertir a num√©rica\n",
        "if 'required_age' in df.columns:\n",
        "    df['required_age'] = pd.to_numeric(df['required_age'], errors='coerce')\n",
        "\n",
        "    # Tabla de probabilidades por edad\n",
        "    pmf = (\n",
        "        df['required_age']\n",
        "        .value_counts(normalize=True)\n",
        "        .sort_index()\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.bar(pmf.index, pmf.values, color=\"steelblue\")\n",
        "    plt.title(\"PMF ‚Äî Probabilidad de cada Edad Requerida en Steam\")\n",
        "    plt.xlabel(\"Edad requerida\")\n",
        "    plt.ylabel(\"Probabilidad\")\n",
        "    plt.xticks(pmf.index)   # muestra cada edad exacta en el eje X\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"La columna 'required_age' no se encuentra en el dataset.\")"
      ],
      "metadata": {
        "id": "yNyH8xljDeRo"
      },
      "id": "yNyH8xljDeRo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## La PDF es una versi√≥n suavizada del histograma.\n",
        "## Nos muestra d√≥nde se concentran m√°s los precios y la forma general de su distribuci√≥n.\n",
        "## Permite ver picos, colas y densidades sin el ruido del histograma."
      ],
      "metadata": {
        "id": "v_BzPs13jbCM"
      },
      "id": "v_BzPs13jbCM"
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(df['price'].dropna(), fill=True)\n",
        "plt.title(\"PDF ‚Äî Densidad de Precios\")\n",
        "plt.xlabel(\"Precio\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VvR_WbHDeT9_"
      },
      "id": "VvR_WbHDeT9_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## La CDF indica qu√© porcentaje de los juegos tiene un precio menor o igual a un valor X.\n",
        "## Ayuda a entender r√°pidamente c√≥mo se acumulan los precios y en qu√© rangos est√° la mayor√≠a."
      ],
      "metadata": {
        "id": "AAu5QuPeji5d"
      },
      "id": "AAu5QuPeji5d"
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.sort(df['price'].dropna())\n",
        "y = np.arange(1, len(x)+1) / len(x)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(x, y)\n",
        "plt.title(\"CDF ‚Äî Distribuci√≥n Acumulada de Precios\")\n",
        "plt.xlabel(\"Precio\")\n",
        "plt.ylabel(\"Probabilidad Acumulada\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZnND8Ud_ebN1"
      },
      "id": "ZnND8Ud_ebN1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.regplot(data=df, x='positive_ratings', y='negative_ratings',\n",
        "            scatter_kws={'alpha':0.3}, line_kws={'color':'red'})\n",
        "plt.title(\"Relaci√≥n entre Reviews Positivas y Negativas (con regresi√≥n)\")\n",
        "plt.xlabel(\"Reviews Positivas\")\n",
        "plt.ylabel(\"Reviews Negativas\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jqHL9BD0pLl-"
      },
      "id": "jqHL9BD0pLl-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.regplot(data=df, x='positive_ratings', y='total_reviews',\n",
        "            scatter_kws={'alpha':0.3}, line_kws={'color':'red'})\n",
        "plt.title(\"Relaci√≥n entre Reviews Positivas y Total de Reviews (con regresi√≥n)\")\n",
        "plt.xlabel(\"Reviews Positivas\")\n",
        "plt.ylabel(\"Total de Reviews\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3GpkZoXuR7Aa"
      },
      "id": "3GpkZoXuR7Aa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.regplot(data=df, x='price', y='total_reviews',\n",
        "            scatter_kws={'alpha':0.3}, line_kws={'color':'red'})\n",
        "plt.title(\"Relaci√≥n entre Precio y Total de Reviews (con regresi√≥n)\")\n",
        "plt.xlabel(\"Precio (‚Ç¨)\")\n",
        "plt.ylabel(\"Total de Reviews\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "njH3rQ5VR-Yx"
      },
      "id": "njH3rQ5VR-Yx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(18,5))\n",
        "\n",
        "# 1. positive_ratings vs negative_ratings\n",
        "sns.regplot(data=df, x='positive_ratings', y='negative_ratings',\n",
        "            scatter_kws={'alpha':0.3}, line_kws={'color':'red'}, ax=axs[0])\n",
        "axs[0].set_title(\"Positivas vs Negativas\")\n",
        "axs[0].set_xlabel(\"Reviews Positivas\")\n",
        "axs[0].set_ylabel(\"Reviews Negativas\")\n",
        "\n",
        "# 2. positive_ratings vs total_reviews\n",
        "sns.regplot(data=df, x='positive_ratings', y='total_reviews',\n",
        "            scatter_kws={'alpha':0.3}, line_kws={'color':'red'}, ax=axs[1])\n",
        "axs[1].set_title(\"Positivas vs Total Reviews\")\n",
        "axs[1].set_xlabel(\"Reviews Positivas\")\n",
        "axs[1].set_ylabel(\"Total Reviews\")\n",
        "\n",
        "# 3. price vs total_reviews\n",
        "sns.regplot(data=df, x='price', y='total_reviews',\n",
        "            scatter_kws={'alpha':0.3}, line_kws={'color':'red'}, ax=axs[2])\n",
        "axs[2].set_title(\"Precio vs Total Reviews\")\n",
        "axs[2].set_xlabel(\"Precio (‚Ç¨)\")\n",
        "axs[2].set_ylabel(\"Total Reviews\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qIPQx3IvSEvR"
      },
      "id": "qIPQx3IvSEvR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "X = df['positive_ratings']\n",
        "y = df['total_reviews']\n",
        "\n",
        "X = sm.add_constant(X)\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# ----- RESULTADOS -----\n",
        "params = modelo.params\n",
        "conf_int = modelo.conf_int()\n",
        "\n",
        "print(\"üìå REGRESI√ìN LINEAL SIMPLE\")\n",
        "print(\"Ecuaci√≥n:\")\n",
        "print(f\"total_reviews = {params['const']:.3f} + {params['positive_ratings']:.6f} * positive_ratings\")\n",
        "\n",
        "print(\"\\nüìä M√âTRICAS:\")\n",
        "print(f\"R¬≤ = {modelo.rsquared:.3f}  ({modelo.rsquared*100:.1f}%)\")\n",
        "print(f\"p-valor pendiente = {modelo.pvalues['positive_ratings']:.6f}\")\n",
        "print(f\"IC95% pendiente = [{conf_int.loc['positive_ratings',0]:.6f}, {conf_int.loc['positive_ratings',1]:.6f}]\")\n",
        "\n",
        "print(\"\\nüß† INTERPRETACI√ìN:\")\n",
        "print(f\"A mas reviews positivas, mas reviews totales.\")\n",
        "print(f\"Significativo: {'S√≠' if modelo.pvalues['positive_ratings'] < 0.05 else 'No'}\")\n"
      ],
      "metadata": {
        "id": "5LeySBAXSJIT"
      },
      "id": "5LeySBAXSJIT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "import numpy as np\n",
        "\n",
        "# Create 'rating_ratio' column\n",
        "# Ensure total_reviews is not zero before division\n",
        "df['rating_ratio'] = df.apply(\n",
        "    lambda row: row['positive_ratings'] / row['total_reviews'] if row['total_reviews'] > 0 else np.nan,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Create 'owners_avg' column by parsing the 'owners' string\n",
        "def parse_owners(owners_str):\n",
        "    if pd.isna(owners_str):\n",
        "        return np.nan\n",
        "\n",
        "    # Remove commas for easier conversion\n",
        "    owners_str = owners_str.replace(',', '')\n",
        "\n",
        "    parts = owners_str.split('-')\n",
        "    if len(parts) == 2:\n",
        "        try:\n",
        "            lower = int(parts[0])\n",
        "            upper = int(parts[1])\n",
        "            return (lower + upper) / 2\n",
        "        except ValueError:\n",
        "            return np.nan # Handle cases where conversion to int fails\n",
        "    elif len(parts) == 1: # Handle cases like '100000' (single value, if any)\n",
        "        try:\n",
        "            return int(parts[0])\n",
        "        except ValueError:\n",
        "            return np.nan\n",
        "    return np.nan # Default for unhandled formats\n",
        "\n",
        "df['owners_avg'] = df['owners'].apply(parse_owners)\n",
        "\n",
        "# Limpiar datos\n",
        "df_test = df[['rating_ratio', 'owners_avg']].dropna()\n",
        "\n",
        "# Test de correlaci√≥n\n",
        "corr, p_value = pearsonr(df_test['rating_ratio'], df_test['owners_avg'])\n",
        "\n",
        "print(f\"Correlaci√≥n Pearson: {corr:.3f}\")\n",
        "print(f\"p-value: {p_value:.5f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Se rechaza H‚ÇÄ: existe relaci√≥n significativa entre valoraciones y owners.\")\n",
        "else:\n",
        "    print(\"No se puede rechazar H‚ÇÄ.\")"
      ],
      "metadata": {
        "id": "feXeOIeBCc2E"
      },
      "id": "feXeOIeBCc2E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear variable binaria free vs paid\n",
        "df['pricing_model'] = df['price'].apply(lambda x: 'Free-to-Play' if x == 0 else 'Paid')\n",
        "\n",
        "# Filtrar datos v√°lidos\n",
        "df_box = df[['pricing_model', 'owners_avg']].dropna()\n",
        "\n",
        "# Boxplot comparativo\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.boxplot(x='pricing_model', y='owners_avg', data=df_box)\n",
        "plt.ylabel('N√∫mero estimado de Owners')\n",
        "plt.xlabel('Modelo de negocio')\n",
        "plt.title('Comparaci√≥n de Owners: Juegos Free-to-Play vs de Pago')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RsRwAoGtLQlh"
      },
      "id": "RsRwAoGtLQlh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "43guvJVhLQSt"
      },
      "id": "43guvJVhLQSt"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}